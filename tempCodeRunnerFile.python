import pandas as pd
import numpy as np
from sklearn.utils import shuffle
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import tensorflow_hub as hub

try:
  # %tensorflow_version only exists in Colab.
  %tensorflow_version 2.x
except Exception:
  pass

!pip install tensorflow-hub
!pip install tfds-nightly
import tensorflow_hub as hub
import tensorflow_datasets as tfds

print("Version: ", tf.__version__)
print("Eager mode: ", tf.executing_eagerly())
print("Hub version: ", hub.__version__)
print("GPU is", "available" if tf.config.experimental.list_physical_devices("GPU") else "NOT AVAILABLE")

sql = pd.read_csv('/content/drive/My Drive/SQL Injection Detection/Data/sql.csv')
password = pd.read_csv('/content/drive/My Drive/SQL Injection Detection/Data/password.csv')
username = pd.read_csv('/content/drive/My Drive/SQL Injection Detection/Data/username.csv')
sqli = pd.read_csv('/content/drive/My Drive/SQL Injection Detection/Data/sqli.csv')

username.dropna(axis=0, how="all", inplace=True)
password.dropna(axis=0, how="all", inplace=True)
username.reset_index(drop=True, inplace=True)
password.reset_index(drop=True, inplace=True)

from google.colab import drive
drive.mount('/content/drive')

def leng(df, col, len_col):
  df[len_col] = df[col].apply(lambda x: len(str(x)))
  return df

username = leng(username, 'Query', 'Length')
password = leng(password, 'Query', 'Length')
sql = leng(sql, 'Query', 'Length')

username['Label'] = 'username'
password['Label'] = 'password'
sqli['Label'] = 'sqli'
sql['Label'] = 'sql'

sqli.drop(['Attack'], axis=1, inplace=True)
username.drop(['Attack'], axis=1, inplace=True)
password.drop(['Attack'], axis=1, inplace=True)
sql.drop(['Attack'], axis=1, inplace=True)

df = pd.concat([sqli, sql, username, password])
df.reset_index(drop=True, inplace=True)

def cal_puncndop(df, col, punop_col, l):
  df1 = df[[col]].copy()
  df[punop_col] = 0
  for i, query in enumerate(df[col]):
    count = 0
    li = list(query)
    for ch in range(len(query)):
      if query[ch] in l:
        li[ch] = " "
        count = count + 1
    df1[col][i] = "".join(li)
    df[punop_col][i] = count
  df[col] = df1[col]
  return df

df = cal_puncndop(df, 'Query', 'punctuation', ['!', ",", "\'", ";", "\"", ".", "-", "?", "[", "]", ")", "("])
df.head()

def cal_keyword(df, col, key_col, l):
  df[key_col] = 0
  for i, query in enumerate(df[col]):
    count = 0
    query = query.lower()
    words = query.split()
    for word in words:
      if word in l:
        count = count + 1
    df[key_col][i] = count
  return df

df = cal_keyword(df, 'Query', 'keyword', ["select", "update", "insert", "create", "drop", "alter", "rename", "exec", "order", "group", "sleep", "count", "where"])
df.head()

for i, label in enumerate(df['Label']):
  if label in ['sql', 'username', 'password']:
    df['Label'][i] = 'non-sqli'

def encode_categorical(df, column_list):
  for column in column_list:
    df[column] = df[column].astype('str')
    encoder = preprocessing.LabelEncoder()
    df[column] = encoder.fit_transform(df[column])
    print("The", column, "is encoded")
  return df

df = encode_categorical(df, ['Label'])

X = np.array(df.drop(labels=['Label', 'Query'], axis=1))
y = np.array(df['Label'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))
test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))

BATCH_SIZE = 64
SHUFFLE_BUFFER_SIZE = 100

train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
test_dataset = test_dataset.batch(BATCH_SIZE)

embedding = "https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1"
hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)

model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(20, activation='relu', input_shape=(X.shape[1],)))
model.add(tf.keras.layers.Dense(16, activation='relu'))
model.add(tf.keras.layers.Dense(1))

model.summary()

model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(train_dataset,
                    epochs=20,
                    verbose=1)

model.evaluate(test_dataset)
